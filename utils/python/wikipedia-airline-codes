#!/usr/bin/env python

import requests
from bs4 import BeautifulSoup
from urlparse import urlparse, parse_qs

import os
import sys
import csv

if __name__ == "__main__":

    url = "https://en.wikipedia.org/wiki/List_of_airline_codes"
    rsp = requests.get(url)

    soup = BeautifulSoup(rsp.content, 'html.parser')

    t = soup.find("table", attrs={"class":"wikitable"})
    body = t.find("tbody")

    writer = None
    
    for row in body.find_all("tr"):

        cols = row.find_all("td")

        if len(cols) == 0:
            continue
        
        iata_col = cols[0]
        icao_col = cols[1]
        airline_col = cols[2]
        callsign_col = cols[3]

        link_col = airline_col.find("a")
        link = ""
        
        if link_col:
            
            link = link_col.attrs.get("href", None)

            if link.startswith("/wiki/"):
                link = link.replace("/wiki/", "")
            elif link.startswith("/w/index.php?"):

                parsed_url = urlparse(link)
                q = parse_qs(parsed_url.query)
                link = q["title"][0]
                
            else:
                link = ""
                
        iata_code = iata_col.text.strip()
        icao_code = icao_col.text.strip()
        airline = airline_col.text.strip()
        callsign = callsign_col.text.strip()

        out = {
            "iata_code": iata_code.encode("utf8"),
            "icao_code": icao_code.encode("utf8"),
            "name": airline.encode("utf8"),
            "callsign": callsign.encode("utf8"),
            "wikipedia_id": link.encode("utf8"),
        }

        if not writer:

            writer = csv.DictWriter(sys.stdout, fieldnames=out.keys())
            writer.writeheader()

        writer.writerow(out)
        
